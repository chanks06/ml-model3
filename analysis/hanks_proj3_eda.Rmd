---
title: "Project 3"
author: "Charles Hanks & Karol Orozco"
date: "03/16/2023"
output:
  pdf_document:
    df_print: kable
    fig_width: 11
    fig_height: 8
  html_document:
    df_print: paged
---





## Setup
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = '/Users/charleshanks/repos/ml-model3/datasets')


library(tidyverse)
library(tidytext)
library(caret)
library(fastDummies)
library(randomForest)
# https://www.openml.org/d/1590

options(scipen=999)


```

```{r}
getwd()
raw_income = read_csv("openml_1590.csv", na=c("?"))

income = read_csv("openml_1590.csv", na=c("?")) %>%
  drop_na() %>%
  mutate(income_above_50k = class==">50K") %>%
  select(-class) %>%
  dummy_cols(remove_selected_columns = T)

#formatting col names: 
raw_income = raw_income %>% rename_all(funs(str_replace_all(.,"-","_"))) %>% 
                rename_all(funs(tolower(.)))

income = income %>% rename_all(funs(str_replace_all(.,"-","_"))) %>% 
                rename_all(funs(tolower(.)))
```

## Some questions about the data

Please try at least a few of the following:

* Run PCA on the dataset. How many principal components do you need to explain half the variation? 
* Can you give some interpretation of the principal components?
* Look at the scree plot. How many PCs would you choose based on that?
* Are the first few Principal Components good predictors of income_above_50k?
* How well can you predict income_above_50k using the first 5 or 6 principal components? How about only the first 2?
* Can you gain any insights into the data based on k-means clustering? 
* Can you visualize and interpret some or all of your clusters?
* Using any and all techniques we have learned, build the best predictive model for income_above_50k that you can. What are your best features? What model did you use? What interpretations can you draw?
* What metric can you use to assess model performance? Why is that a good choice of metric in this case?
* What are some key insights you found through your analysis?

Please remember: a statement like "PC2 is not a meaningful predictor for our modeling problem" is a great insight; sometimes things don't work!

10 pts PCA

* analysis and interpretation of factor loadings
* discussion of scree plot and/or analysis of some density plots of PCs
* meaningful interpretation / discussion of conclusions 

10 pts k-means

* discussion for choosing number of clusters
* analysis of cluster centers
* bivariate chart(s) against meaningful variables and/or analysis of density plots
* meaningful interpretation / discussion of conclusions 

10 pts supervised learning

* feature engineering / selection, whether with PCA or otherwise
* interpretation of variable importance, coefficients if applicable
* justification of choice of metric
* discussion of choice or tuning of hyperparameters, if any
* meaningful discussion of predictive power and conclusions from model

Please be prepared to 

* Submit your Rmd + compiled html or pdf, *and*
* Present your findings to the class in a compelling way, speaking for 10 minutes or so. You don't need to cover everything in your analysis that you submit to me, focus on the fun / interesting / compelling highlights or challenges.


####

# BACKGROUND

- Prediction task is to determine whether a person makes over 50k a year. Data from 1994 Census database. 
- fnlwgt: demographic background of the people - people with similar demographic characteristics should have similar weights. 


```{r}
library(skimr)
skim(income)


```

# Transforming capital gain and capital loss: 
```{r}
ggplot(income, aes(x = capital_loss)) + geom_histogram()
#I should log capital-gain and capital-loss
#definition: capital gain refers to the increase in the value of a capital asset when it is sold. A capital gain occurs when you sell an asset for more than what you originally paid for it. 

income = income %>% mutate(l_capital_gain = log(capital_gain), 
                  l_capital_loss = log(capital_loss)) %>% 
                        select(-capital_gain,-capital_loss)

#moving these cols back to front of dummy cols: 
income = income %>% relocate(l_capital_gain, l_capital_loss)

#center and scaling capital_gain and capital_loss: 
#income = income %>% select(capital_gain, capital_loss) %>% preProcess(method = c("center", "scale")) %>% predict(income) 


#changing -Inf back to 0 for log transformed vars: 
income = income %>% mutate(l_capital_gain = ifelse(l_capital_gain == -Inf, 0, l_capital_gain),
                  l_capital_loss = ifelse(l_capital_loss == -Inf, 0, l_capital_loss))

#Now checking out shape of log transformed data: 
ggplot(income, aes(x = l_capital_loss)) + geom_histogram() + xlim(6,12)
```

# Exploratory Data Analysis 

```{r}
#what is education_num? 
#is NA retired? Unemployed? 


#looking at age vs. occupation: 
raw_income %>% ggplot(aes(x = age, fill = occupation)) + geom_histogram() + facet_wrap(~occupation)
#military is a younger person's occupation 
#exec-manegerial is very normally distributed 
```

Distribution of careers by gender 
```{r}
raw_income %>% 
  group_by(occupation,sex) %>% 
          count() %>% 
          ggplot(aes(x = occupation, y = n, fill = sex)) + geom_col() + coord_flip()

#craft-repair, farming/fishing, executive mostly male, admin mostly female 
#there are some ethical considerations to unpack here in building this model...

```

```{r}
raw_income %>% group_by(education, workclass) %>% count() %>% ggplot(aes(x = n, y = education, fill = workclass)) + geom_col()
```
Examining distribution by sex: 
```{r}
raw_income %>% group_by(relationship) %>% summarize(avg_age= mean(age))

n_sex = raw_income %>% 
  group_by(sex) %>% 
    count()

n_sex %>%
    ggplot(aes(x = sex, y = n, fill = sex)) + geom_col()
#there are twice as many men in this dataset....may need to downsample by gender later in the game. This may lead to implicit bias toward men making more than 50k in the model. 

raw_income %>% group_by(sex, class) %>% count() %>% mutate(prop = n/nrow(raw_income))
#there is 1 female husband, look like this dataset does not take into account the difference between gender and sex
#yikes, only 3.6 % of this dataset includes women who make more than 50k! 

```
# Age 

```{r}
income

ggplot(income, aes(x = income_above_50k, y = age, fill = income_above_50k)) + geom_boxplot()

income %>% group_by(income_above_50k) %>% summarize(med_age = median(age), avg_age = mean(age))

ggplot(income, aes(x = age)) + geom_histogram(binwidth = 10)

income = income %>% mutate(age_bin = 
                    case_when( 
                      age < 20 ~ "teen", 
                      age >=20 & age <30 ~ "20-29",
                      age >=30 & age <40 ~ "30-39", 
                      age >=40 & age <50 ~ "40-50",
                      age >=50 & age <66 ~ "50-65",
                      age >=65  ~ "65+")
                                          ) %>% 
                                    relocate(age_bin) %>% 
                                          relocate(l_capital_gain, l_capital_loss)

income$age_bin = factor(income$age_bin, levels = c("teen", "20-29","30-39","40-50","50-65","65+"))

#distribution of people by age bin
ggplot(income, aes(x = age_bin, fill = age_bin)) + geom_histogram(stat= 'count')

ggplot(income, aes(x = age_bin)) + geom_histogram(stat = 'count',aes(fill = income_above_50k)) + facet_wrap(~income_above_50k)
#People in their forties are most likely to be making above 50k. 

```
Is there a correlation between education level and income over 50k ? 
```{r}
raw_income %>% ggplot(aes(x = class, y = fnlwgt)) + geom_col()

raw_income = raw_income %>% mutate(above_50k = ifelse(class == '<=50K',0,1))

cor.test(raw_income$`education-num`,raw_income$above_50k)

# correlation coeffcient is .33, not super strong.
```
What countries are represented in this dataset? 

```{r}
unique(raw_income$native_country)

#how many of each country? 

raw_income %>% group_by(native_country) %>% count() %>% arrange(desc(n)) %>% mutate(prop = n/nrow(raw_income))
#almost 90% are native citizen of USA, about 10 % have immigrate in their life time. 
#1.7 % do not have a native country listed. 

#I'm guessing that if you're white, male and from USA, there is a higher probability of making > 50k....


```

Is there a correlation between # of hours worked per week and income over 50k ? 

```{r}
cor.test(raw_income$hours_per_week, raw_income$above_50k)
#.22 correlation coef 

income = income %>% mutate(work_over40 = ifelse(hours_per_week > 40,1,0)) %>% relocate(work_over40) %>% relocate(l_capital_gain:hours_per_week)

#graph that 

income %>% group_by(work_over40, income_above_50k) %>% count() %>% ggplot(aes(x = work_over40, y = n, fill = income_above_50k)) + geom_col()

#answer: there are almost the same amount of folks who do / don't work over 40 hours who have income over 50k. However, the proportion of people who make over 50k and work over 40 is 40% that subgroup, compared to 18% of people who do make over 50 k and do not work over 40 hours per week. 

```


```{r}
age_bin_dummies = income %>% select(age_bin) %>% 
    dummy_cols(remove_selected_columns = T)

income.2 = bind_cols(income,age_bin_dummies) %>% select(-age_bin)
```

# Principal Component Analysis on income dataset

```{r}
pr_income = prcomp(x = select(income.2,-income_above_50k), scale = T, center = T)

summary(pr_income)
#it takes 38 PCA features to explain 50% of the variation in the data. 
```

```{r}
screeplot(pr_income, type = "lines")
#elbow is around pc5
```

Factor loadings: 

```{r}
pr_income$rotation
#PC1 : works longer hours, less private work, older
#PC2 : lower education level, less local government, more private work, younger
#PC3 : older, less private sector (not very meaningfu predictor) 
#PC4 : younger, more educated 
#PC5 : ...
#PC6 : public workers 
#PC7 : work long hours in private sector 
#PC8 : low fnlwgt...not quite sure how to interpret this variable yet. less private sector work 
#the min/max seems to be around abs(+/-.2)
```

filtering principal component with threshold of highest impact 

```{r}
rownames_to_column(as.data.frame(pr_income$rotation)) %>% 
  select(1:6) %>% 
    filter(abs(PC1) >= 0.3 | abs(PC2) >= 0.3 | abs(PC3) >= 0.3 | abs(PC4) >= 0.3 | abs(PC5) >= 0.3)

```
```{r}
prc = bind_cols(select(income.2, income_above_50k), as.data.frame(pr_income$x)) %>%
  select(1:6) %>%
    rename("married_men" = PC1, "uneducated" = PC2, "usborn_educated" = PC3, "usborn_white"= PC4, "nonwhite_less_work" = PC5)

prc %>%
pivot_longer(cols = -income_above_50k, names_to = "component", values_to = "loading") %>% mutate(income_above_50k = as.factor(income_above_50k)) %>%
ggplot(aes(loading, fill=income_above_50k)) +
geom_density(alpha = 0.5) +
facet_grid(.~component)

#principal compoenents "married_men" (PC1) and "uneducated" (PC4) are best predictors of income_above_50k, but not the rest. If I had to choose one one to carry with me it would be married_men (PC1) to include in a model. 


```
married_men vs. uneducated principal components
```{r}
prc %>%
select(income_above_50k, married_men, uneducated) %>%
pivot_longer(cols = -income_above_50k,names_to = "component",values_to = "loading") %>%
ggplot(aes(loading, fill=income_above_50k))+
geom_density(alpha=0.5)+
facet_grid(.~component)

```

Making a model using only  5 PCs: 

```{r}
prc = prc %>% mutate(income_above_50k = ifelse(income_above_50k == TRUE, "y", "n"))
prc = prc %>% mutate(income_above_50k = as.factor(income_above_50k))

ctrl <- trainControl(method = "cv", number = 3, classProbs = TRUE)

prc_index <- createDataPartition(prc$income_above_50k, p = 0.80, list = FALSE)
train <- prc[prc_index, ]
test <- prc[-prc_index, ]

model.pca =train(income_above_50k ~ .,
             data = train, 
             method = "rf",
             metric = "ROC",
             trControl = ctrl)

importance = varImp(model.pca)
plot(importance)

#var imp plot confirms that pc1 "married_men" is the most predictive of class

```

# K-MEANS clustering 


```{r}
income.2.no.Y = income.2 %>% select(-income_above_50k)
income.2.no.Y = na.omit(income.2.no.Y)

kclust = kmeans(income.2.no.Y, centers = 5)

?kmeans()

?na_omit()
```

